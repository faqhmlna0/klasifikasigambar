# -*- coding: utf-8 -*-
"""Proyek Akhir Dicoding Machine Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BXdsbAezJ-UzDGUO2z5UtgvSDGqRHLC4

# Data Diri
```
Nama: Muhammad Faqih Maulana
Username: faqhmlna
Emai: faqhmlna@gmail.com
```

## Machine Learning
"""

# Import Library
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from google.colab import files
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os
import shutil

# Import Dataset menggunakan !wget
!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip

# Melakukan ekstraksi pada file zip
import zipfile,os
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

# Membagi File Sesuai arahan 60% dan 40% menggunakan Splitfolders
!pip install split-folders
import splitfolders
input_dir = '/tmp/rockpaperscissors'
output_dir = '/tmp/rockpaperscissors_split'

# 60% Train dan 40% Validation
splitfolders.ratio(input_dir, output=output_dir, seed=42, ratio=(0.6, 0.4))

# Membuat directory untuk data training dan validation
base_dir = '/tmp/rockpaperscissors_split'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')

# Menghapus direktori 'rps-cv-images' agar tidak mengganggu
path_to_remove = os.path.join(train_dir, 'rps-cv-images')
if os.path.exists(path_to_remove):
  shutil.rmtree(path_to_remove)

path_to_remove = os.path.join(validation_dir, 'rps-cv-images')
if os.path.exists(path_to_remove):
  shutil.rmtree(path_to_remove)

# Memeriksa Direktori Train
os.listdir('/tmp/rockpaperscissors_split/train')

# Memeriksa Direktori Validation
os.listdir('/tmp/rockpaperscissors_split/val')

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Melakukan Augmentation
train_datagen = ImageDataGenerator(
                    rescale = 1./255,
                    rotation_range = 20,
                    horizontal_flip = True,
                    shear_range = 0.2,
                    fill_mode = 'nearest',
                    width_shift_range = 0.2,
                    height_shift_range = 0.2,
                    zoom_range = 0.1)

test_datagen = ImageDataGenerator(
                    rescale = 1./255)

train_generator = train_datagen.flow_from_directory(
          train_dir, # Direktori data latih
          target_size=(150,150),  # Mengubah resolusi seluruh gambar menjadi 150x150 piksel
          batch_size=4,
          # karena ini merupakan masalah klasifikasi 3 kelas, gunakan class_mode = 'categorical'
          class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
          validation_dir, # Direktori data validasi
          target_size=(150,150),  # Mengubah resolusi seluruh gambar menjadi 150x150 piksel
          batch_size=4,
          class_mode='categorical')

# Menggunakan Model sequential
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2), # Mereduksi resolusi gambar
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2), # Mereduksi resolusi gambar
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2), # Mereduksi resolusi gambar
    tf.keras.layers.Conv2D(528, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2), # Mereduksi resolusi gambar
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

# Mengcompile Model
model.compile(loss='categorical_crossentropy', # Dikarenakan Classes Menggunakan Categorical (Lebih dari 3)
              optimizer='rmsprop', # Pake Adam kurang baik hasilnya jadi coba pake rmsprop
              metrics=['accuracy'])

# Menghentikan dengan callback
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, mode='max', verbose=1)

# Melatih model dengan fit
model.fit(
    train_generator,
    steps_per_epoch=25,
    epochs=35, # Tergantung dengan Akurasi Model
    validation_data=validation_generator,
    validation_steps=5,
    callbacks=[early_stopping],
    verbose=2)

print(train_generator.class_indices)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=1)
  classes_predict = np.argmax(classes[0])

  print(fn)
  if classes_predict == 0:
    print('paper')
  elif classes_predict == 1:
    print('rock')
  else:
    print('scissors')